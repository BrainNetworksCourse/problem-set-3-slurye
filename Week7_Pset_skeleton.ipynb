{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem set: Week 7 (Resting fMRI)\n",
    "In this problem set you will load the correlation data from one of the Midnight Scan Club subjects (which has already been extracted using the Glasser MMP parcellation) and perform several analyses to characterize the network.\n",
    "\n",
    "As before, skeletal code is provided - please fill in any areas where you see ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,pickle,sys\n",
    "import numpy,pandas\n",
    "import nilearn.datasets\n",
    "import nilearn.plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import networkx as nx\n",
    "import sklearn.metrics\n",
    "import bct\n",
    "from collections import Counter\n",
    "\n",
    "from brainnetworks.r2z import r_to_z,z_to_r\n",
    "%matplotlib inline\n",
    "\n",
    "datadir = nilearn.datasets.get_data_dirs()[0]\n",
    "if not os.path.exists(datadir):\n",
    "    os.mkdir(datadir)\n",
    "    \n",
    "atlasdir='/home/vagrant/brain-networks-course/data/HCP-MMP1'\n",
    "\n",
    "labelfile=os.path.join(atlasdir,'MMP_yeo2011_networks.csv')\n",
    "labeldata=pandas.read_csv(labelfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first load the data\n",
    "\n",
    "sub=1\n",
    "corrtype='gsr'  # use data with global signal regression\n",
    "scrubtype='full' # don't use scrubbing\n",
    "\n",
    "\n",
    "subdir=os.path.join(datadir,'MSC/ds000224/derivatives/fmriprep/sub-MSC%02d/'%sub)\n",
    "\n",
    "corrs=pickle.load(open(os.path.join(subdir,'sub-MSC%02d_task-rest_corrmtx.pkl'%sub),'rb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the mean correlation matrix across sesssions, using the r-to-z transform to first convert them to Z scores and then convert back to r values after averaging. The correlation data are stored in a dictionary, with the following key structure:\n",
    "\n",
    "> ```corrs[session num][corrtype:{'gsr','nogsr'}][scrubtype:{'scrubbed','full'}]```\n",
    "\n",
    "We will use corrtype and scrubtype as specified above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagrant/anaconda3/envs/py3/lib/python3.6/site-packages/brainnetworks/r2z.py:9: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  z=0.5*numpy.log((1.0+r)/(1.0-r))\n"
     ]
    }
   ],
   "source": [
    "corrsum=numpy.zeros(corrs[1][corrtype][scrubtype].shape)\n",
    "for s in corrs:\n",
    "    sesscor=corrs[s][corrtype][scrubtype]\n",
    "    corrsum+=r_to_z(sesscor)\n",
    "    \n",
    "meancorr=z_to_r(corrsum/len(corrs))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1**: Create a binary adjacency matrix with a density of 5%, and use this to create a NetworkX graph.  Be sure to do the following:\n",
    "\n",
    "- exclude the diagonal when computing the cutoff \n",
    "- zero out the diagonal before creating the graph\n",
    "- extract the giant component from the graph (calling the resulting variable ```Gc```)\n",
    "- print the number of nodes in the giant component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagrant/anaconda3/envs/py3/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Giant component includes 356 out of 360 total nodes\n"
     ]
    }
   ],
   "source": [
    "# determine cutoff for 5% density of the correlation matrix\n",
    "# using just the upper triangle of the matrix\n",
    "thresh=95  # in percent\n",
    "cutoff=scipy.stats.scoreatpercentile(meancorr[numpy.triu_indices_from(meancorr,1)],\n",
    "                                         thresh) \n",
    "\n",
    "#create symmetric binary adjacency matrix\n",
    "# be sure to convert to integer\n",
    "adjmtx=(meancorr>cutoff).astype('int')\n",
    "\n",
    "# zero out the diagonal in the adjmtx\n",
    "adjmtx[numpy.diag_indices_from(adjmtx)]=0\n",
    "\n",
    "# Create numpy graph\n",
    "G=nx.from_numpy_array(adjmtx)\n",
    "\n",
    "# create graph for giant component\n",
    "# first get all component subgraphs\n",
    "comps=[i for i in nx.connected_component_subgraphs(G)]\n",
    "# then take the largest\n",
    "Gc=comps[0]\n",
    "\n",
    "print('Giant component includes %d out of %d total nodes'%(len(Gc.nodes),len(G.nodes)))\n",
    "\n",
    "# grab the label data for only the nodes in the giant component\n",
    "labeldata_Gc=labeldata.loc[list(Gc.nodes)]\n",
    "# add degree values to labeldata frame\n",
    "labeldata_Gc['degree']=[Gc.degree[i] for i in labeldata_Gc.index]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3**: Perform community detection on the graph, using the Louvain algorithm for undirected binary graphs as implemented in the bct python package, and compute their overlap with the Yeo 7 network parcellation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vagrant/anaconda3/envs/py3/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modularity: 0.6556898453842146\n",
      "Multilevel modularity optimization identifed 7 communities\n",
      "Adjusted Rand index compared to Yeo 7 networks: 0.393\n"
     ]
    }
   ],
   "source": [
    "Gc_nodelist=list(Gc.nodes)\n",
    "tmp=meancorr[Gc_nodelist,:]\n",
    "meancorr_Gc=tmp[:,Gc_nodelist]\n",
    "cutG=scipy.stats.scoreatpercentile(meancorr[numpy.triu_indices_from(meancorr,1)],\n",
    "                                         thresh) \n",
    "adjmtx_Gc=(meancorr_Gc>cutG).astype('int')\n",
    "adjmtx_Gc[numpy.diag_indices_from(adjmtx_Gc)]=0\n",
    "\n",
    "mod_binary=bct.modularity_louvain_und(adjmtx_Gc)\n",
    "\n",
    "print('modularity:',mod_binary[1])\n",
    "print('Multilevel modularity optimization identifed %d communities'%len(numpy.unique(mod_binary[0])))\n",
    "\n",
    "# compute adjusted rand score using method from sklearn.metrics\n",
    "ari=sklearn.metrics.adjusted_rand_score(mod_binary[0],labeldata_Gc['Yeo7'])\n",
    "print('Adjusted Rand index compared to Yeo 7 networks: %0.3f'%ari)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 4**: Estimate the normalized rich club coefficient for this network and plot the coefficients across the range of degree values.  Find the smallest degree value  for which the rich club coefficient is greater than 2, which we will use to define the rich club nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree_cutoff: 36\n",
      "41 nodes in rich club\n"
     ]
    }
   ],
   "source": [
    "# embed computation of rcc within a try/catch since it fails\n",
    "# pretty regularly with a ZeroDivisionError\n",
    "good_rcc=False\n",
    "while not good_rcc:\n",
    "    try:\n",
    "        rcc = nx.rich_club_coefficient(Gc,True)\n",
    "        good_rcc=True\n",
    "    except ZeroDivisionError:\n",
    "        print('error, retrying')\n",
    "        \n",
    "# put into a data frame\n",
    "rccdata=pandas.DataFrame([(i,rcc[i]) for i in rcc.keys()],\n",
    "                         columns=['degree','rcc'])\n",
    "# find the degree cutoff for rcc >= 2\n",
    "val = 0\n",
    "for index, row in rccdata.iterrows():\n",
    "    if row['rcc'] >= 2:\n",
    "        val = index\n",
    "        break\n",
    "degree_cutoff = val\n",
    "print('degree_cutoff:',degree_cutoff) \n",
    "rcclist = []\n",
    "for node in Gc.degree:\n",
    "    index, deg = node\n",
    "    if deg >= degree_cutoff:\n",
    "        rcclist.append(index)\n",
    "# compute the size of the rich club\n",
    "rc_size= len(rcclist)\n",
    "print(rc_size,'nodes in rich club')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 5:** For each of the Yeo7 networks, determine how many rich club members fall within that network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 12, 15, 16, 18, 20, 42, 59, 107, 142, 145, 157, 158, 183, 184, 185, 186, 192, 195, 196, 198, 201, 209, 222, 229, 238, 279, 285, 287, 288, 292, 321, 322, 325, 327, 337, 338, 346, 348]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "59",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-64e2db777741>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrcclist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m labeldata_rcc=pandas.DataFrame([(i,rcc[i]) for i in rcclist],\n\u001b[0m\u001b[1;32m      5\u001b[0m                          columns=['degree','rcc'])\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-64e2db777741>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrcclist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m labeldata_rcc=pandas.DataFrame([(i,rcc[i]) for i in rcclist],\n\u001b[0m\u001b[1;32m      5\u001b[0m                          columns=['degree','rcc'])\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 59"
     ]
    }
   ],
   "source": [
    "# first create a data frame containing label data just for rcc members\n",
    "\n",
    "print(rcclist)\n",
    "labeldata_rcc=pandas.DataFrame([(i,rcc[i]) for i in rcclist],\n",
    "                         columns=['degree','rcc'])\n",
    "\n",
    "# use collections.Counter to generate a list of the counts of members in each\n",
    "# Yeo7 network\n",
    "c=labeldata_rcc.Counter(labeldata_rcc['YeoDesc7'])\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 6:** First, compute the node betweenness centrality and edge betweeness centrality for the giant component network.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute edge betweenness centrality\n",
    "ebc= nx.edge_betweenness_centrality(Gc)\n",
    "\n",
    "# compute node betweenness centrality\n",
    "bc= nx.betweenness_centrality(Gc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, compute the mean betweenness centrality for edges separated by whether they include 0, 1, or 2 members of the rich club, and print out the mean values for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute the mean betweenness centrality for nodes, separated by whether the nodes are members of the rich club or not, and print the values for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does centrality of both nodes and edges relate to rich club membership?  Please explain (insert your answer in the following cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
